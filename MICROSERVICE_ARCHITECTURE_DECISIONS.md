# Microservice Architecture Design Document

## X Authorization Service - Blueprint for Future Services

---

## üìã **PROJECT CONTEXT**

### Current State

- **Codebase**: Standalone Python automation scripts (not a running application)
- **Components**:
  - GoLogin session management (`gologin_session_monitor.py`)
  - Browser automation with Selenium (`browser_startup_handler.py`)
  - Cloudflare challenge handling (`cloudflare_handler.py`)
  - SQLite database for session tracking
  - Threading-based background tasks
  - File-based logging

### Objective

Build the **first microservice** (X Authorization Service) that will serve as the **architectural template** for all future microservices. This is Service #1 in a growing microservice ecosystem.

### Success Criteria

- Production-ready X OAuth automation service
- Reusable patterns for future services (Service #2, #3, etc.)
- Modern Python microservice architecture
- Scalable, observable, testable

---

## üéØ **ARCHITECTURAL DECISIONS NEEDED**

### **1Ô∏è‚É£ TECH STACK - FastAPI vs Flask?**

#### Option A: FastAPI ‚≠ê RECOMMENDED

**Pros:**

- ‚úÖ Built-in async/await support (better for I/O-bound tasks)
- ‚úÖ Automatic OpenAPI/Swagger documentation
- ‚úÖ Pydantic validation (type-safe requests/responses)
- ‚úÖ Better performance (ASGI vs WSGI)
- ‚úÖ Modern Python standards (type hints, async)
- ‚úÖ Growing ecosystem, active development

**Cons:**

- ‚ùå Smaller community than Flask
- ‚ùå Steeper learning curve for async patterns

**Use Cases:**

- APIs with heavy I/O (database, external APIs, Selenium waits)
- Services requiring type safety and validation
- Teams familiar with modern Python

#### Option B: Flask

**Pros:**

- ‚úÖ Mature ecosystem (10+ years)
- ‚úÖ Simpler synchronous model
- ‚úÖ Larger community and more libraries
- ‚úÖ More tutorials and resources

**Cons:**

- ‚ùå WSGI-based (blocking, slower)
- ‚ùå Manual validation setup
- ‚ùå No built-in API documentation

**Use Cases:**

- Simple CRUD APIs
- Teams preferring synchronous code

#### **QUESTION:** Which framework do you prefer?

**Recommendation:** **FastAPI** (aligns with modern microservice practices)

---

### **2Ô∏è‚É£ PROJECT STRUCTURE - Monorepo vs Polyrepo?**

#### Option A: Monorepo (Single Repository)

```
automation-platform/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ x-auth-service/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ future-service-2/
‚îÇ   ‚îî‚îÄ‚îÄ future-service-3/
‚îú‚îÄ‚îÄ shared/
‚îÇ   ‚îú‚îÄ‚îÄ common/          # Shared utilities
‚îÇ   ‚îú‚îÄ‚îÄ models/          # Shared data models
‚îÇ   ‚îú‚îÄ‚îÄ logging/         # Logging configuration
‚îÇ   ‚îî‚îÄ‚îÄ database/        # DB utilities
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îú‚îÄ‚îÄ docker/          # Docker Compose files
‚îÇ   ‚îú‚îÄ‚îÄ kubernetes/      # K8s manifests
‚îÇ   ‚îî‚îÄ‚îÄ terraform/       # Infrastructure as Code
‚îú‚îÄ‚îÄ scripts/             # Build/deployment scripts
‚îî‚îÄ‚îÄ README.md
```

**Pros:**

- ‚úÖ Easy code sharing between services
- ‚úÖ Atomic commits across services
- ‚úÖ Simplified dependency management
- ‚úÖ Single CI/CD pipeline

**Cons:**

- ‚ùå Larger repository size over time
- ‚ùå Tight coupling if not disciplined
- ‚ùå All teams need access to entire repo

#### Option B: Polyrepo (Separate Repositories)

```
x-auth-service/           (Repository 1)
‚îú‚îÄ‚îÄ app/
‚îú‚îÄ‚îÄ tests/
‚îî‚îÄ‚îÄ Dockerfile

future-service-2/         (Repository 2)

shared-python-lib/        (Repository 3 - PyPI package)
‚îú‚îÄ‚îÄ microservices_common/
‚îî‚îÄ‚îÄ setup.py
```

**Pros:**

- ‚úÖ Service isolation
- ‚úÖ Independent versioning
- ‚úÖ Smaller codebases
- ‚úÖ Team ownership boundaries

**Cons:**

- ‚ùå Code sharing requires package publishing
- ‚ùå Cross-service changes need multiple PRs
- ‚ùå More complex CI/CD setup

#### **QUESTION:** Do you prefer monorepo or polyrepo?

**Recommendation:** **Monorepo** (easier to start, can split later if needed)

---

### **3Ô∏è‚É£ SERVICE TEMPLATE STRUCTURE**

#### Proposed Layered Architecture

```
x-auth-service/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ v1/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ endpoints/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.py           # OAuth endpoints
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ jobs.py           # Job management
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health.py         # Health checks
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requests.py       # Pydantic request models
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ responses.py      # Pydantic response models
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dependencies.py       # FastAPI dependencies
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ middleware.py             # Request logging, auth
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ router.py                 # API router
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py                 # Settings (Pydantic BaseSettings)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logging.py                # Structured logging setup
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ security.py               # Encryption, auth helpers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py                # Prometheus metrics
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ exceptions.py             # Custom exceptions
‚îÇ   ‚îú‚îÄ‚îÄ domain/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ oauth_service.py      # Business logic
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ job_service.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repositories/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user_repository.py    # DB access layer
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ job_repository.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py                 # SQLAlchemy models
‚îÇ   ‚îú‚îÄ‚îÄ automation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gologin/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ session_manager.py    # Port existing code
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ profile_manager.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ selenium/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ browser_handler.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ startup_handler.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cloudflare/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ challenge_handler.py
‚îÇ   ‚îî‚îÄ‚îÄ main.py                       # FastAPI app entry point
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_oauth_service.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_cloudflare_handler.py
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_api_endpoints.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_database.py
‚îÇ   ‚îî‚îÄ‚îÄ e2e/
‚îÇ       ‚îî‚îÄ‚îÄ test_full_oauth_flow.py
‚îú‚îÄ‚îÄ migrations/                       # Alembic DB migrations
‚îÇ   ‚îú‚îÄ‚îÄ versions/
‚îÇ   ‚îî‚îÄ‚îÄ env.py
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ init_db.py
‚îÇ   ‚îî‚îÄ‚îÄ seed_data.py
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îú‚îÄ‚îÄ base.yaml
‚îÇ   ‚îú‚îÄ‚îÄ development.yaml
‚îÇ   ‚îî‚îÄ‚îÄ production.yaml
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ pyproject.toml
‚îî‚îÄ‚îÄ README.md
```

#### Architectural Layers Explained

**API Layer** (`app/api/`)

- HTTP endpoints and request handling
- Request validation (Pydantic)
- Response serialization
- API versioning support

**Core Layer** (`app/core/`)

- Cross-cutting concerns
- Configuration management
- Logging, metrics, security
- Reusable utilities

**Domain Layer** (`app/domain/`)

- Business logic (services)
- Data access (repositories)
- Domain models (DB entities)
- No framework dependencies

**Automation Layer** (`app/automation/`)

- GoLogin integration
- Selenium browser automation
- Cloudflare handling
- Platform-specific code

#### **QUESTION:** Does this structure work, or do you have a different architecture preference?

**Recommendation:** **Adopt this layered structure** (clean architecture, testable, maintainable)

---

### **4Ô∏è‚É£ SERVICE COMMUNICATION - Inter-Service Communication**

#### Scenario: Service #2 needs X auth tokens from Service #1

#### Option A: Synchronous REST API

```python
# Service #2 calls Service #1
response = httpx.get(
    "http://x-auth-service:8000/api/v1/auth/token/user123",
    headers={"Authorization": f"Bearer {service_token}"}
)
token = response.json()["oauth_token"]
```

**Pros:**

- ‚úÖ Simple, easy to debug
- ‚úÖ Immediate response
- ‚úÖ Works with existing HTTP infrastructure

**Cons:**

- ‚ùå Tight coupling between services
- ‚ùå Cascading failures (if Service #1 is down, Service #2 fails)
- ‚ùå Synchronous blocking

#### Option B: Asynchronous Message Queue

```python
# Service #1 publishes event
await message_broker.publish("user.authenticated", {
    "user_id": "user123",
    "oauth_token": "..."
})

# Service #2 subscribes to event
@message_broker.subscribe("user.authenticated")
async def handle_auth_event(message):
    token = message["oauth_token"]
```

**Technologies:**

- RabbitMQ (mature, feature-rich)
- Redis Pub/Sub (simple, fast)
- Apache Kafka (high throughput, overkill for small scale)

**Pros:**

- ‚úÖ Loose coupling (services don't need to know about each other)
- ‚úÖ Resilience (retry, dead-letter queues)
- ‚úÖ Scalable (multiple consumers)

**Cons:**

- ‚ùå More complex infrastructure
- ‚ùå Eventual consistency
- ‚ùå Harder to debug

#### Option C: Hybrid (REST + Events)

- **REST**: For queries (`GET /token/{user_id}`)
- **Events**: For commands (`user.login.requested`, `user.authenticated`)

#### **QUESTION:** What's your vision for inter-service communication?

**Recommendation:**

- **Now (1-2 services):** REST API (simpler)
- **Future (3+ services):** Add message queue for events

---

### **5Ô∏è‚É£ SHARED CODE - Reusable Components Across Services**

Every microservice needs:

- Structured logging configuration
- Prometheus metrics collection
- Database connection pooling
- Error handling patterns
- Health check endpoints
- Configuration management

#### Option A: Internal Shared Package (Monorepo)

```
shared/
‚îú‚îÄ‚îÄ microservices_common/
‚îÇ   ‚îú‚îÄ‚îÄ logging.py
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py
‚îÇ   ‚îú‚îÄ‚îÄ database.py
‚îÇ   ‚îú‚îÄ‚îÄ middleware.py
‚îÇ   ‚îî‚îÄ‚îÄ exceptions.py

# In each service
from shared.microservices_common import setup_logging
```

**Pros:**

- ‚úÖ Easy to share and update
- ‚úÖ No publishing overhead
- ‚úÖ Atomic changes

**Cons:**

- ‚ùå Requires monorepo
- ‚ùå Can lead to tight coupling

#### Option B: PyPI Package

```bash
pip install company-microservices-common
```

**Pros:**

- ‚úÖ Works with polyrepo
- ‚úÖ Versioned dependencies
- ‚úÖ Enforces API stability

**Cons:**

- ‚ùå Publishing overhead
- ‚ùå Version management complexity

#### Option C: Code Template (Copy-Paste)

Each service copies the boilerplate code.

**Pros:**

- ‚úÖ Service independence
- ‚úÖ No shared dependencies

**Cons:**

- ‚ùå Code duplication
- ‚ùå Hard to maintain consistency

#### Option D: Sidecar Pattern

Common functionality runs in a separate container alongside each service.

**Pros:**

- ‚úÖ Language-agnostic
- ‚úÖ Centralized updates

**Cons:**

- ‚ùå Infrastructure complexity
- ‚ùå Overkill for small scale

#### **QUESTION:** How should shared code be managed?

**Recommendation:**

- **Monorepo:** Option A (internal shared package)
- **Polyrepo:** Option B (PyPI package)

---

### **6Ô∏è‚É£ DATABASE STRATEGY - One DB per Service or Shared?**

#### Microservice Principle

> Each service should own its data and database schema

#### Option A: One Database per Service ‚≠ê RECOMMENDED

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  X Auth Service     ‚îÇ
‚îÇ  PostgreSQL DB      ‚îÇ
‚îÇ  - users            ‚îÇ
‚îÇ  - oauth_tokens     ‚îÇ
‚îÇ  - jobs             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Service #2         ‚îÇ
‚îÇ  PostgreSQL DB      ‚îÇ
‚îÇ  - service2_data    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Pros:**

- ‚úÖ Service independence (deploy/scale separately)
- ‚úÖ No cross-service data coupling
- ‚úÖ Technology flexibility (Postgres, MongoDB, etc.)
- ‚úÖ True microservice architecture

**Cons:**

- ‚ùå More infrastructure to manage
- ‚ùå Cross-service queries require API calls
- ‚ùå Distributed transactions complexity

#### Option B: Shared Database with Schemas

```
shared-db (PostgreSQL)
‚îú‚îÄ‚îÄ x_auth schema
‚îÇ   ‚îú‚îÄ‚îÄ users
‚îÇ   ‚îî‚îÄ‚îÄ oauth_tokens
‚îî‚îÄ‚îÄ service2 schema
    ‚îî‚îÄ‚îÄ service2_data
```

**Pros:**

- ‚úÖ Simpler infrastructure
- ‚úÖ Easy cross-service queries (anti-pattern in microservices)
- ‚úÖ Single backup/restore

**Cons:**

- ‚ùå Tight coupling between services
- ‚ùå Schema migration conflicts
- ‚ùå Violates microservice principles

#### **QUESTION:** Which database strategy?

**Recommendation:** **One database per service** (true microservices, scalable)

---

### **7Ô∏è‚É£ CONFIGURATION MANAGEMENT**

#### Option A: Environment Variables Only ‚≠ê SIMPLE

```bash
# .env file
DATABASE_URL=postgresql://user:pass@localhost:5432/xauth
GOLOGIN_TOKEN=xyz123
LOG_LEVEL=INFO
REDIS_URL=redis://localhost:6379
ANTICAPTCHA_API_KEY=abc123
```

```python
# app/core/config.py
from pydantic import BaseSettings

class Settings(BaseSettings):
    database_url: str
    gologin_token: str
    log_level: str = "INFO"

    class Config:
        env_file = ".env"

settings = Settings()
```

**Pros:**

- ‚úÖ Simple, 12-factor app compliant
- ‚úÖ Works with Docker, K8s, cloud platforms
- ‚úÖ No extra infrastructure

**Cons:**

- ‚ùå No centralized management
- ‚ùå Hard to update config without restart

#### Option B: Config Files + Environment Override

```yaml
# configs/base.yaml
database:
  pool_size: 10

# configs/production.yaml
database:
  pool_size: 50
```

**Pros:**

- ‚úÖ Complex configurations easier to manage
- ‚úÖ Environment-specific overrides

**Cons:**

- ‚ùå File management complexity
- ‚ùå Secrets in files (security risk)

#### Option C: External Config Service

- **Consul** (HashiCorp)
- **etcd** (Kubernetes-native)
- **AWS Parameter Store / Secrets Manager**

**Pros:**

- ‚úÖ Centralized config management
- ‚úÖ Dynamic updates without restart
- ‚úÖ Built-in secret encryption

**Cons:**

- ‚ùå Additional infrastructure
- ‚ùå Network dependency for startup

#### **QUESTION:** What configuration approach?

**Recommendation:**

- **Now:** Environment variables + Pydantic
- **Future:** Add external config service when you have 5+ services

---

### **8Ô∏è‚É£ AUTHENTICATION & AUTHORIZATION**

#### A. Service-to-Service Authentication

#### Option 1: API Keys

```python
# Service #2 calls Service #1
headers = {"X-API-Key": "service2-secret-key"}
```

**Pros:**

- ‚úÖ Simple
- ‚úÖ Easy to implement

**Cons:**

- ‚ùå Less secure (static keys)
- ‚ùå Hard to rotate

#### Option 2: JWT Tokens ‚≠ê RECOMMENDED

```python
# Service #1 issues token to Service #2
token = create_service_token(service_id="service2")

# Service #2 uses token
headers = {"Authorization": f"Bearer {token}"}
```

**Pros:**

- ‚úÖ Stateless
- ‚úÖ Can include claims (service_id, permissions)
- ‚úÖ Time-limited (automatic expiry)

**Cons:**

- ‚ùå Requires shared secret or PKI

#### Option 3: mTLS (Mutual TLS)

**Pros:**

- ‚úÖ Most secure
- ‚úÖ Certificate-based

**Cons:**

- ‚ùå Complex setup
- ‚ùå Certificate management overhead

#### B. Client-to-Service Authentication

**Who calls your API?**

- Other internal services?
- Frontend applications?
- Third-party integrations?
- Admin users?

#### **QUESTION:** What authentication model do you need?

**Recommendation:**

- **Service-to-service:** JWT tokens
- **Client-to-service:** API keys (simple) or OAuth2 (if complex auth needed)

---

### **9Ô∏è‚É£ DEVELOPMENT WORKFLOW**

#### Option A: Full Docker Compose

```bash
# Start everything in Docker
docker-compose up

# All services + dependencies running in containers
# - x-auth-service
# - postgres
# - redis
# - prometheus
```

**Pros:**

- ‚úÖ Matches production environment
- ‚úÖ Consistent across team
- ‚úÖ Easy onboarding

**Cons:**

- ‚ùå Slower development cycle (rebuild images)
- ‚ùå More resource-intensive
- ‚ùå Harder to debug

#### Option B: Hybrid (Service Local, Dependencies in Docker) ‚≠ê RECOMMENDED

```bash
# Start dependencies only
docker-compose up postgres redis

# Run service locally
python -m uvicorn app.main:app --reload
```

**Pros:**

- ‚úÖ Fast development (hot reload)
- ‚úÖ Easy debugging
- ‚úÖ Resource-efficient

**Cons:**

- ‚ùå Slight difference from production

#### Option C: Kubernetes-Native (Tilt/Skaffold)

```bash
tilt up
```

**Pros:**

- ‚úÖ Matches production K8s environment
- ‚úÖ Auto-rebuild and redeploy

**Cons:**

- ‚ùå Requires local K8s (minikube, kind)
- ‚ùå Steeper learning curve

#### **QUESTION:** What's your team's preferred development workflow?

**Recommendation:** **Hybrid approach** (dependencies in Docker, service runs locally)

---

### **üîü DEPLOYMENT PIPELINE**

#### CI/CD Stages

```yaml
# .github/workflows/ci-cd.yml or .gitlab-ci.yml

stages: 1. Lint & Format
  - black (code formatting)
  - ruff (linting)
  - mypy (type checking)

  2. Test
  - pytest unit tests
  - pytest integration tests
  - coverage report (minimum 80%)

  3. Security Scan
  - bandit (Python security)
  - safety (dependency vulnerabilities)
  - trivy (Docker image scan)

  4. Build
  - Docker image build
  - Tag with version
  - Push to registry

  5. Deploy
  - Development (auto-deploy on merge to main)
  - Staging (manual approval)
  - Production (manual approval + smoke tests)
```

#### **QUESTIONS:**

1. Do you have existing CI/CD infrastructure (GitHub Actions, GitLab CI, Jenkins)?
2. Where will you deploy? (AWS, GCP, Azure, on-premise)
3. Container registry preference? (Docker Hub, ECR, GCR, private registry)

**Recommendation:** GitHub Actions (if on GitHub) or GitLab CI (if on GitLab)

---

### **1Ô∏è‚É£1Ô∏è‚É£ OBSERVABILITY - Logging, Metrics, Tracing**

#### A. Logging

#### Structured JSON Logging

```python
# Instead of:
logger.info("User logged in: user123")

# Use:
logger.info(
    "user_login_success",
    user_id="user123",
    profile_id="profile456",
    duration_ms=1250,
    ip_address="192.168.1.1"
)

# Output:
{
  "timestamp": "2025-09-30T10:15:30Z",
  "level": "INFO",
  "event": "user_login_success",
  "user_id": "user123",
  "profile_id": "profile456",
  "duration_ms": 1250,
  "request_id": "req-abc123",
  "service": "x-auth-service"
}
```

**Libraries:**

- `structlog` (recommended)
- `python-json-logger`

**Centralized Logging:**

- ELK Stack (Elasticsearch, Logstash, Kibana)
- Loki + Grafana
- AWS CloudWatch Logs
- GCP Cloud Logging

#### B. Metrics

**Prometheus + Grafana** (industry standard)

```python
from prometheus_client import Counter, Histogram, Gauge

# Counters
oauth_attempts = Counter(
    'oauth_attempts_total',
    'Total OAuth attempts',
    ['status', 'service']
)

# Histograms (duration tracking)
oauth_duration = Histogram(
    'oauth_duration_seconds',
    'OAuth flow duration'
)

# Gauges (current state)
active_sessions = Gauge(
    'active_browser_sessions',
    'Number of active browser sessions'
)

# Usage
@oauth_duration.time()
def run_oauth_flow():
    try:
        # ... automation ...
        oauth_attempts.labels(status='success', service='x-auth').inc()
    except Exception:
        oauth_attempts.labels(status='failure', service='x-auth').inc()
```

**Key Metrics to Track:**

- Request rate, latency, error rate (RED method)
- OAuth success/failure rates
- Cloudflare challenge solve rates
- Browser session durations
- Queue depths (if using message queue)

#### C. Distributed Tracing

**OpenTelemetry** (unified standard)

```python
from opentelemetry import trace

tracer = trace.get_tracer(__name__)

@tracer.start_as_current_span("oauth_flow")
def run_oauth_flow(user_id: str):
    with tracer.start_as_current_span("start_browser"):
        browser = start_gologin_session()

    with tracer.start_as_current_span("solve_cloudflare"):
        solve_cloudflare_challenge(browser)

    with tracer.start_as_current_span("authenticate"):
        oauth_token = perform_oauth(browser)

    return oauth_token
```

**Trace Backends:**

- Jaeger
- Zipkin
- AWS X-Ray
- Google Cloud Trace

#### **QUESTIONS:**

1. Do you have existing observability infrastructure?
2. Preference for cloud-native (Datadog, New Relic) vs self-hosted (ELK, Prometheus)?

**Recommendation:**

- **Logging:** structlog + JSON output (can send to any log aggregator)
- **Metrics:** Prometheus + Grafana
- **Tracing:** OpenTelemetry (start simple, can add later)

---

### **1Ô∏è‚É£2Ô∏è‚É£ ERROR HANDLING & RESILIENCE**

#### Patterns to Include

#### A. Global Exception Handler

```python
# app/api/middleware.py
from fastapi import Request, status
from fastapi.responses import JSONResponse

@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    logger.error(
        "unhandled_exception",
        error=str(exc),
        path=request.url.path,
        request_id=request.state.request_id
    )

    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={
            "success": false,
            "error_code": "INTERNAL_ERROR",
            "error_message": "An unexpected error occurred",
            "request_id": request.state.request_id
        }
    )
```

#### B. Retry Logic with Exponential Backoff

```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10)
)
def call_gologin_api():
    # Retries up to 3 times with exponential backoff
    response = requests.get("https://api.gologin.com/...")
    response.raise_for_status()
    return response.json()
```

#### C. Circuit Breaker Pattern

```python
from pybreaker import CircuitBreaker

# If 5 failures occur, open circuit for 60 seconds
gologin_breaker = CircuitBreaker(
    fail_max=5,
    timeout_duration=60
)

@gologin_breaker
def start_gologin_session():
    # If circuit is open, raises CircuitBreakerError immediately
    # instead of trying (prevents cascading failures)
    pass
```

#### D. Graceful Degradation

```python
# If captcha solver is down, return partial result
try:
    captcha_token = solve_captcha_with_service()
except CaptchaSolverUnavailable:
    logger.warning("captcha_solver_unavailable", fallback="manual")
    return {
        "success": false,
        "error_code": "CAPTCHA_REQUIRED",
        "error_message": "Captcha requires manual intervention",
        "captcha_url": "...",
        "retry_after": 300
    }
```

#### E. Dead Letter Queue (for async jobs)

```python
# If job fails after all retries, move to DLQ for manual review
if retry_count >= MAX_RETRIES:
    await dead_letter_queue.publish(job_data)
    logger.error("job_moved_to_dlq", job_id=job_id)
```

#### **QUESTION:** How sophisticated should error handling be?

**Recommendation:**

- Include A, B (essential for production)
- Add C, D, E as services scale

---

## üéØ **RECOMMENDED ARCHITECTURE (MVP)**

Based on modern microservice best practices, here's what I recommend for **Service #1**:

### Tech Stack

- ‚úÖ **FastAPI** (async, modern, type-safe)
- ‚úÖ **PostgreSQL** (production-ready, one DB per service)
- ‚úÖ **Redis** (caching, job queue)
- ‚úÖ **Docker + Docker Compose** (containerization)

### Repository Structure

- ‚úÖ **Monorepo** (easier to start, shared code management)
- ‚úÖ **Layered architecture** (API ‚Üí Domain ‚Üí Infrastructure)

### Communication

- ‚úÖ **REST API** (simple, synchronous)
- üîÆ **Message queue later** (when you have 3+ services)

### Shared Code

- ‚úÖ **Internal shared package** (`shared/microservices_common`)

### Configuration

- ‚úÖ **Environment variables + Pydantic** (12-factor app)

### Security

- ‚úÖ **JWT for service-to-service auth**
- ‚úÖ **Encrypted DB fields** for sensitive data
- ‚úÖ **API keys for client-to-service**

### Development Workflow

- ‚úÖ **Hybrid:** Dependencies in Docker, service runs locally
- ‚úÖ **Hot reload** for fast iteration

### CI/CD

- ‚úÖ **GitHub Actions** (if on GitHub) or **GitLab CI**
- ‚úÖ Automated tests, linting, security scans
- ‚úÖ Docker image build and push

### Observability

- ‚úÖ **Structured JSON logging** (structlog)
- ‚úÖ **Prometheus metrics** (RED method)
- ‚úÖ **Request correlation IDs**
- üîÆ **OpenTelemetry tracing later** (when debugging distributed issues)

### Error Handling

- ‚úÖ **Global exception handlers**
- ‚úÖ **Retry with exponential backoff**
- ‚úÖ **Proper error response contracts**

### Database

- ‚úÖ **One PostgreSQL database per service**
- ‚úÖ **Alembic for migrations**
- ‚úÖ **SQLAlchemy async ORM**

---

## üìä **DECISION MATRIX**

| Decision       | Option Chosen                | Rationale                                          |
| -------------- | ---------------------------- | -------------------------------------------------- |
| Framework      | FastAPI                      | Modern, async, type-safe, auto-docs                |
| Repo Structure | Monorepo                     | Easier to start, shared code management            |
| Architecture   | Layered (API/Domain/Infra)   | Clean, testable, maintainable                      |
| Database       | PostgreSQL (one per service) | Production-ready, scalable, microservice principle |
| Config         | Environment Variables        | Simple, 12-factor compliant                        |
| Service Auth   | JWT Tokens                   | Stateless, secure, industry standard               |
| Dev Workflow   | Hybrid (deps in Docker)      | Fast iteration, easy debugging                     |
| CI/CD          | GitHub Actions               | Native to GitHub, free for public repos            |
| Logging        | Structured JSON (structlog)  | Machine-parseable, works with all log aggregators  |
| Metrics        | Prometheus + Grafana         | Industry standard, powerful                        |
| Error Handling | Global handlers + retries    | Resilient, production-ready                        |

---

## üöÄ **IMPLEMENTATION PHASES**

### Phase 1: Core Service (Week 1-2)

- [ ] Project scaffolding (folder structure, dependencies)
- [ ] FastAPI app setup with API endpoints
- [ ] Database models and migrations
- [ ] Port existing automation code (GoLogin, Selenium, Cloudflare)
- [ ] Pydantic request/response models
- [ ] Basic error handling
- [ ] Docker Compose setup

**Deliverable:** Working X Auth service locally

### Phase 2: Production-Ready (Week 3-4)

- [ ] Structured logging (JSON)
- [ ] Prometheus metrics
- [ ] Unit tests (80% coverage)
- [ ] Integration tests
- [ ] JWT authentication
- [ ] Encrypt sensitive DB fields
- [ ] Health check endpoints
- [ ] Graceful shutdown handling
- [ ] Documentation (API docs, README)

**Deliverable:** Production-ready service

### Phase 3: Deployment & Observability (Week 5-6)

- [ ] CI/CD pipeline (GitHub Actions)
- [ ] Kubernetes manifests (optional)
- [ ] Prometheus + Grafana dashboards
- [ ] Alerting rules
- [ ] E2E tests
- [ ] Load testing
- [ ] Security hardening

**Deliverable:** Deployed service with full observability

### Phase 4: Scale & Optimize (Month 2+)

- [ ] Circuit breakers
- [ ] Rate limiting
- [ ] Caching strategy
- [ ] Message queue integration (if needed)
- [ ] External secret manager
- [ ] Advanced monitoring (tracing)

**Deliverable:** Battle-tested, scalable service

---

## ‚ùì **QUESTIONS FOR DISCUSSION**

### Critical (Need Answers Before Starting)

1. **Framework:** FastAPI or Flask?
2. **Repository:** Monorepo or polyrepo?
3. **Service Communication:** REST only, or plan for message queue?
4. **Database:** PostgreSQL acceptable? Other preferences?
5. **Deployment Target:** Where will this run? (AWS/GCP/Azure/on-premise/local)
6. **Existing Infrastructure:** Any CI/CD, logging, monitoring already in place?

### Important (Can Use Defaults if Uncertain)

7. **Shared Code:** Internal package vs PyPI package vs code templates?
8. **Authentication:** JWT tokens acceptable for service-to-service?
9. **Development Workflow:** Hybrid (deps in Docker) acceptable?
10. **Observability:** Prometheus + structlog acceptable, or existing stack?

### Nice to Have (Can Decide Later)

11. **Message Queue:** RabbitMQ vs Redis vs Kafka (if needed)?
12. **Secret Management:** When to add external secret manager?
13. **Tracing:** When to add OpenTelemetry?
14. **Testing:** E2E test frequency (nightly, manual, per-PR)?

---

## üìù **NEXT STEPS**

Once you provide answers to the critical questions, I can:

1. **Scaffold the entire microservice** with production-ready patterns
2. **Port existing automation code** into the new structure
3. **Set up Docker Compose** for local development
4. **Configure CI/CD pipeline** (GitHub Actions or GitLab CI)
5. **Write comprehensive documentation**
6. **Create database migrations**
7. **Implement health checks and metrics**

---

## üìö **REFERENCE ARCHITECTURE**

This design follows:

- ‚úÖ **12-Factor App** principles
- ‚úÖ **Clean Architecture** (Uncle Bob)
- ‚úÖ **Microservice patterns** (Sam Newman)
- ‚úÖ **Domain-Driven Design** concepts
- ‚úÖ **SOLID principles**
- ‚úÖ **Python best practices** (PEP 8, type hints)

**Similar Systems:**

- Uber's microservice architecture
- Netflix's service mesh
- Shopify's service platform

---

**Document Version:** 1.0  
**Last Updated:** September 30, 2025  
**Author:** AI Architect  
**Status:** Awaiting Decisions
